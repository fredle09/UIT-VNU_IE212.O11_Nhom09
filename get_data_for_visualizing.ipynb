{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26670ea0-d921-44f3-88f8-2ddcca85b3c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bin.config import *\n",
    "from bin.consumer import Consumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9563649-0f69-41e8-9591-92e098b573a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark_session: SparkSession = (\n",
    "    SparkSession.builder.appName(\"Consumer data for Visualizing\")  # type: ignore\n",
    "    .config(\"spark.jars.packages\", \",\".join(SPARK_PACKAGES))\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20c1209a-0407-424d-bad4-f84af05bfdb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "capture_con: Consumer = Consumer(\n",
    "    topic=CAPTURE_TOPIC,\n",
    "    schema_list=CAPTURE_SCHEMA_LIST,\n",
    "    spark_session=spark_session,\n",
    ")\n",
    "\n",
    "segment_con: Consumer = Consumer(\n",
    "    topic=SEGMENT_TOPIC,\n",
    "    schema_list=SEGMENT_SCHEMA_LIST,\n",
    "    spark_session=spark_session,\n",
    ")\n",
    "\n",
    "prediction_con: Consumer = Consumer(\n",
    "    topic=PREDICTION_TOPIC,\n",
    "    schema_list=PREDICTION_SCHEMA_LIST,\n",
    "    spark_session=spark_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57b83937-e2ae-4d97-a0ec-00a61c493924",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_FILE_NAME: str = f\"{BATCH_FOLDER}batch.csv\"\n",
    "CACHE_FILE_NAME: str = f\"{BATCH_FOLDER}cache.csv\"\n",
    "PREDICTION_FILE_NAME: str = f\"{BATCH_FOLDER}prediction.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6afb81a-87a1-4511-a033-93366fee0fe0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def store_dataframe_to_csv(df: DataFrame, path: str, **kwargs) -> None:\n",
    "    return df.toPandas().to_csv(path, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c2c636-dc72-4527-9beb-b20e7fb7feab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def handle_batch_event_table(event_df: DataFrame, epoch_id: int) -> None:\n",
    "#     result: DataFrame = event_df.join(segment_table, on=\"SegmentID\", how=\"inner\")\n",
    "#     store_dataframe_to_csv(result, BATCH_NAME_FILE, header=True, index=False)\n",
    "    \n",
    "#     result = (\n",
    "#         result.groupBy(\"Boro\", \"Timestamp\")\n",
    "#         .agg(F.sum(F.col(\"Vol\")), F.count(F.col(\"Vol\")))\n",
    "#         .withColumn(\"Avg(Vol)\", F.col(\"Sum(Vol)\") / F.col(\"Count(Vol)\"))\n",
    "#         .drop(\"Sum(Vol)\", \"Count(Vol)\")\n",
    "#     )\n",
    "\n",
    "#     store_dataframe_to_csv(\n",
    "#         result, CACHE_NAME_FILE, header=False, index=False, mode=\"a\"\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0f8f84-55ad-4f28-b08e-3eed20950e8c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# streaming_capture_df: DataFrame = capture_con.get_streaming_df()\n",
    "# streaming_capture_query: StreamingQuery = capture_con.handle_batch_streaming_with_callable(\n",
    "#     streaming_df, handle_batch_capture_table\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "# print(\"Streaming query is running...\")\n",
    "\n",
    "# try:\n",
    "#     streaming_query.awaitTermination()\n",
    "# except KeyboardInterrupt:\n",
    "#     print(\"Stopping streaming query...\")\n",
    "#     streaming_query.stop()\n",
    "#     print(\"Streaming query stopped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c25e80b-93f0-4b8f-8c27-ec3fa202b1a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "segment_df: DataFrame = segment_con.get_history_df()\n",
    "capture_history_df: DataFrame = capture_con.get_history_df()\n",
    "prediction_df: DataFrame = prediction_con.get_history_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d53dda8-31aa-45f9-9d4d-8d342d7221b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def callable_handle_batch(prediction_df: DataFrame, epoch_id: int) -> None:\n",
    "#     full_prediction_df: DataFrame = (\n",
    "#         prediction_df.join(segment_df, on=\"SegmentID\", how=\"inner\")\n",
    "#         .groupBy(\"Boro\", \"Timestamp\")\n",
    "#         .agg(F.mean(\"prediction_vol\").alias(\"Vol\"))\n",
    "#         .orderBy(\"Timestamp\", \"Boro\")\n",
    "#     )\n",
    "    \n",
    "#     store_dataframe_to_csv(\n",
    "#         full_prediction_df, \n",
    "#         path=PREDICTION_FILE_NAME,\n",
    "#         header=True,\n",
    "#         index=False,\n",
    "#         mode=\"w+\"\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8604df92-5380-4031-a137-c80ce7707522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_query.stop()\n",
    "\n",
    "# prediction_streaming_df: DataFrame = prediction_con.get_streaming_df()\n",
    "# prediction_query: StreamingQuery = prediction_con.handle_batch_streaming_with_callable(\n",
    "#     prediction_streaming_df, callable_handle_batch\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8a16327-8d00-4d9d-bb4b-c066ff66fff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "window_spec = Window.orderBy(F.col(\"prediction_ds\").desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3bfe31-3d23-4357-9fee-18c319f3eb2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-06-20 06:45:00\n",
      "2017-06-20 03:45:00\n",
      "11.51273\n",
      "2017-06-20 07:00:00\n",
      "2017-06-20 04:00:00\n",
      "6.155432\n",
      "2017-06-20 07:15:00\n",
      "2017-06-20 04:15:00\n",
      "5.409148\n",
      "2017-06-20 07:30:00\n",
      "2017-06-20 04:30:00\n",
      "5.385054\n",
      "2017-06-20 07:45:00\n",
      "2017-06-20 04:45:00\n",
      "5.243362\n",
      "2017-06-20 08:00:00\n",
      "2017-06-20 05:00:00\n",
      "5.056513\n",
      "2017-06-20 08:15:00\n",
      "2017-06-20 05:15:00\n",
      "5.084335\n",
      "2017-06-20 08:30:00\n",
      "2017-06-20 05:30:00\n",
      "4.988272\n",
      "2017-06-20 08:45:00\n",
      "2017-06-20 05:45:00\n",
      "5.070641\n",
      "2017-06-20 09:00:00\n",
      "2017-06-20 06:00:00\n",
      "4.79811\n",
      "2017-06-20 09:15:00\n",
      "2017-06-20 06:15:00\n",
      "5.517992\n",
      "2017-06-20 09:30:00\n",
      "2017-06-20 06:30:00\n",
      "4.780598\n",
      "2017-06-20 09:45:00\n",
      "2017-06-20 06:45:00\n",
      "4.964492\n",
      "2017-06-20 10:00:00\n",
      "2017-06-20 07:00:00\n",
      "4.942403\n",
      "2017-06-20 10:15:00\n",
      "2017-06-20 07:15:00\n",
      "4.716591\n"
     ]
    }
   ],
   "source": [
    "while True:    \n",
    "    point_start_time: datetime = datetime.now()\n",
    "    \n",
    "    current_timestamp: datetime = capture_history_df.agg(F.max(\"Timestamp\")).first()[0]\n",
    "    print(current_timestamp)\n",
    "\n",
    "    minable_timestamp: datetime = current_timestamp - timedelta(hours=EXPIRE_TIME)\n",
    "    print(minable_timestamp)\n",
    "    \n",
    "    cache_history_df: DataFrame = capture_history_df.filter(F.col(\"Timestamp\") > minable_timestamp)\n",
    "    batch_history_df: DataFrame = capture_history_df.filter(F.col(\"Timestamp\") == current_timestamp)\n",
    "    cache_prediction_df: DataFrame = (\n",
    "        prediction_df.withColumn(\"max_prediction_ds\", F.max(\"prediction_ds\").over(window_spec))\n",
    "        .select(\"SegmentID\", \"Timestamp\", \"Direction\", \"prediction_vol\", \"max_prediction_ds\", \"prediction_ds\")\n",
    "        .filter(F.col(\"Timestamp\") > current_timestamp)\n",
    "        .filter(F.col(\"prediction_ds\") == F.col(\"max_prediction_ds\"))\n",
    "        .drop(\"prediction_ds\", \"max_prediction_ds\")\n",
    "    )\n",
    "    full_batch_history_df: DataFrame = (\n",
    "        batch_history_df.join(segment_df, on=[\"SegmentID\"], how=\"inner\")\n",
    "        .groupBy(\"Timestamp\", \"Long\", \"Lat\")\n",
    "        .agg(F.sum(\"Vol\"))\n",
    "    )\n",
    "    store_dataframe_to_csv(\n",
    "        full_batch_history_df,\n",
    "        path=BATCH_FILE_NAME,\n",
    "        header=True,\n",
    "        index=False,\n",
    "        mode=\"w+\"\n",
    "    )\n",
    "    \n",
    "    full_cache_history_df: DataFrame = (\n",
    "        cache_history_df.join(segment_df, on=[\"SegmentID\"], how=\"inner\")\n",
    "        .groupBy(\"Boro\", \"Timestamp\")\n",
    "        .agg(F.mean(\"Vol\").alias(\"Vol\"))\n",
    "        .orderBy(\"Timestamp\", \"Boro\")\n",
    "    )\n",
    "    store_dataframe_to_csv(\n",
    "        full_cache_history_df,\n",
    "        path=CACHE_FILE_NAME,\n",
    "        header=True,\n",
    "        index=False,\n",
    "        mode=\"w+\"\n",
    "    )\n",
    "\n",
    "    full_cache_prediction_df: DataFrame = (\n",
    "        cache_prediction_df.join(segment_df, on=[\"SegmentID\"], how=\"inner\")\n",
    "        .groupBy(\"Boro\", \"Timestamp\")\n",
    "        .agg(F.mean(\"prediction_vol\").alias(\"Vol\"))\n",
    "        .orderBy(\"Timestamp\", \"Boro\")\n",
    "    )\n",
    "    store_dataframe_to_csv(\n",
    "        full_cache_prediction_df,\n",
    "        path=PREDICTION_FILE_NAME,\n",
    "        header=True,\n",
    "        index=False,\n",
    "        mode=\"w+\"\n",
    "    )\n",
    "\n",
    "    timestamp = (datetime.now() - point_start_time).total_seconds()\n",
    "    print(timestamp)\n",
    "    time_to_sleep: float = max(DELAY - timestamp, 0)\n",
    "    sleep(time_to_sleep)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56576462-8ea5-492b-88e3-68afb57a9329",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
